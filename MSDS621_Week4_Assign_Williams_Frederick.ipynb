{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('ml-1m/ratings.dat') as fn:\\n    for line in fn:\\n        print(line)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used this to look at the dat files to see if they loaded properly\n",
    "\"\"\"\n",
    "with open('ml-1m/ratings.dat') as fn:\n",
    "    for line in fn:\n",
    "        print(line)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ml-1m/movies.dat') as dat_file, open('ml-1m/movies.csv', 'w') as csv_file:\n",
    "    ####\n",
    "    #this was used to headers into the csv as a result of misreading the directions\n",
    "    #writer = csv.DictWriter(csv_file, fieldnames=['MovieID', 'Title', 'Year', 'Genre','Genre','Genre', 'Genre'])\n",
    "    #writer.writeheader()\n",
    "    #####\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    for line in dat_file:\n",
    "        if \"::\" in line:\n",
    "            row = line.strip()\n",
    "            row = row.split(\"::\")\n",
    "            row = \"|\".join(row)\n",
    "            row = row.split('|')\n",
    "            row = row[:3]\n",
    "        for i in range(len(row)):\n",
    "            if ',' in row[1]:\n",
    "                row[1] = row[1].replace(',','')\n",
    "        \n",
    "            \n",
    "            \"\"\"\n",
    "        #this loop was use to make the csv much cleaner by separating the \n",
    "        #title and year \n",
    "        for i in range(len(row)):\n",
    "            if '(' in row[i]:\n",
    "                row[i] = row[i].strip()\n",
    "                row[i] = row[i].split(\"(\")\n",
    "                row[i] = \")\".join(row[i])\n",
    "                row[i] = row[i].split(')')\n",
    "                row[i] = row[i][:-1]\n",
    "                titled_row = row[i][0]\n",
    "                year_row = row[i][1]\n",
    "        # created copy of list 'row' as \"new_row\"\n",
    "        #This solution still updates the a list in place. \n",
    "        #To avoid it, change the order of lines: new_row=row[:]; row.insert(2,3)\n",
    "        del row[1]\n",
    "        for j in range(len(row)):\n",
    "            new_row = row[:]\n",
    "            new_row.insert(1,titled_row)\n",
    "            new_row.insert(2, year_row)\n",
    "            \"\"\"\n",
    "        csv.writer(csv_file).writerow(row)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is use to avoid DRY \n",
    "#since the other files have similiar formats\n",
    "#def convert_dat2csv(file_name, header_list):\n",
    "    #with open('ml-1m/{}'.format(file_name)) as file_dat, open('ml-1m/{}.csv'.format(file_name), 'w',newline ='') as file_csv:\n",
    "def convert_dat2csv(file_name):\n",
    "    with open('ml-1m/{}'.format(file_name)) as file_dat, open('ml-1m/{}.csv'.format(file_name), 'w') as file_csv:\n",
    "        #writer = csv.DictWriter(file_csv, fieldnames=header_list)\n",
    "        #writer.writeheader()\n",
    "        csv_writer = csv.writer(file_csv)\n",
    "\n",
    "        for line in file_dat:\n",
    "            if \"::\" in line:\n",
    "                row = line.strip()\n",
    "                row = row.split(\"::\")\n",
    "            for i in range(len(row)):\n",
    "                if '-' in row[4]:\n",
    "                    row[4] = row[4].replace('-','')\n",
    "                    \n",
    "                               \n",
    "            csv.writer(file_csv).writerow(row)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dat_to_csv(file_name):\n",
    "    with open('ml-1m/{}'.format(file_name)) as file_dat, open('ml-1m/{}.csv'.format(file_name), 'w') as file_csv:\n",
    "        #writer = csv.DictWriter(file_csv, fieldnames=header_list)\n",
    "        #writer.writeheader()\n",
    "        csv_writer = csv.writer(file_csv)\n",
    "\n",
    "        for line in file_dat:\n",
    "            if \"::\" in line:\n",
    "                row = line.strip()\n",
    "                row = row.split(\"::\")\n",
    "                    \n",
    "                               \n",
    "            csv.writer(file_csv).writerow(row)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_header = ['UserID', 'MovieID', 'Rating','Timestamp']\n",
    "u_header = ['UserID','Gender', 'Age', 'Occupation', 'ZipCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dat1 = 'users.dat'\n",
    "file_dat2 ='ratings.dat' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dat2csv(file_dat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dat_to_csv(file_dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('ml-1m/ratings.dat.csv') as fn:\\n    for line in fn:\\n        print(line)\\n\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used this to look at the csv files to see how to place the header columns\n",
    "\"\"\"\n",
    "with open('ml-1m/ratings.dat.csv') as fn:\n",
    "    for line in fn:\n",
    "        print(line)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_csv(csv_dirty,csv_clean):\n",
    "    with open('ml-1m/{}'.format(csv_dirty)) as input_csv, open('ml-1m/{}'.format(csv_clean), 'w', newline='') as output:\n",
    "        writer = csv.writer(output)\n",
    "        for row in csv.reader(input_csv):\n",
    "            if any(field.strip() for field in row):\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_csv('movies.csv','clean_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_csv('users.dat.csv','clean_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_csv('ratings.dat.csv','clean_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing CSV into SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new database by changing the name within the quotes\n",
    "conn = psycopg2.connect(host='localhost',\n",
    "                       dbname='postgres',\n",
    "                       user='postgres',\n",
    "                       password='Scizor212')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cursor object \n",
    "#cursor object is used to interact with the database\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-24709a2e5d17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DROP TABLE If Exists \"Movies\";'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "#c.execute('DROP TABLE If Exists \"Movies\";')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CREATE TABLE` command with the columns in the same order as the CSV file and their respective types. Similar to running a `SELECT` query, we will write the command as a string and pass it to the `execute()` method. Hereâ€™s how it would look for this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"\"\"CREATE TABLE Movies\n",
    "(MovieID Integer Primary Key ,\n",
    "Title Text,\n",
    "Genre Text)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''CREATE TABLE Users \n",
    "(UserID Integer Primary Key, \n",
    "Gender Text, \n",
    "Age Integer, \n",
    "Occupation Integer, \n",
    "ZipCode Integer);''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''Create Table Ratings \n",
    "(UserID Integer,\n",
    "MovieID Integer,\n",
    "Rating Integer,\n",
    "Timestamp Integer)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ml-1m/clean_movies.csv', 'r') as f:\n",
    "# Notice that we don't need the `csv` module.\n",
    "#next(f) # Skip the header row.\n",
    "    c.copy_from(f, 'Movies', sep=',')\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ml-1m/clean_users.csv', 'r') as u_csv:\n",
    "    c.copy_from(u_csv, 'Users', sep=',')\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ml-1m/clean_ratings.csv', 'r') as r_csv:\n",
    "    c.copy_from(r_csv, 'Ratings', sep=',')\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to test that all the data was transferred to their assign tables\n",
    "postgresql_select1 = 'Select * From Movies'\n",
    "postgresql_select2 = 'Select * From Users'\n",
    "postgresql_select3 = 'Select * From Ratings'\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(postgresql_select1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Toy Story (1995)', 'Animation'), (2, 'Jumanji (1995)', 'Adventure'), (3, 'Grumpier Old Men (1995)', 'Comedy'), (4, 'Waiting to Exhale (1995)', 'Comedy'), (5, 'Father of the Bride Part II (1995)', 'Comedy'), (6, 'Heat (1995)', 'Action'), (7, 'Sabrina (1995)', 'Comedy'), (8, 'Tom and Huck (1995)', 'Adventure'), (9, 'Sudden Death (1995)', 'Action'), (10, 'GoldenEye (1995)', 'Action')]\n"
     ]
    }
   ],
   "source": [
    "movies_test = cur.fetchmany(10)\n",
    "print(movies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(postgresql_select2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'F', 1, 10, 48067), (2, 'M', 56, 16, 70072), (3, 'M', 25, 15, 55117), (4, 'M', 45, 7, 2460), (5, 'M', 25, 20, 55455), (6, 'F', 50, 9, 55117), (7, 'M', 35, 1, 6810), (8, 'M', 25, 12, 11413), (9, 'M', 25, 17, 61614), (10, 'F', 35, 1, 95370)]\n"
     ]
    }
   ],
   "source": [
    "users_test = cur.fetchmany(10)\n",
    "print(users_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(postgresql_select3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1193, 5, 978300760), (1, 661, 3, 978302109), (1, 914, 3, 978301968), (1, 3408, 4, 978300275), (1, 2355, 5, 978824291), (1, 1197, 3, 978302268), (1, 1287, 5, 978302039), (1, 2804, 5, 978300719), (1, 594, 4, 978302268), (1, 919, 4, 978301368)]\n"
     ]
    }
   ],
   "source": [
    "ratings_test = cur.fetchmany(10)\n",
    "print(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgresql_select4 = \"\"\"\n",
    "Select m.Title,\n",
    "m.Genre,\n",
    "u.UserID,\n",
    "u.Gender,\n",
    "u.Age, \n",
    "u.Occupation,\n",
    "u.ZipCode,\n",
    "r.Rating,\n",
    "r.Timestamp\n",
    "From Movies m\n",
    "Inner Join Ratings r On m.MovieID = r.MovieID\n",
    "Inner Join Users u On r.UserID = u.UserID;\"\"\"\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(postgresql_select4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"One Flew Over the Cuckoo's Nest (1975)\", 'Drama', 1, 'F', 1, 10, 48067, 5, 978300760), ('James and the Giant Peach (1996)', 'Animation', 1, 'F', 1, 10, 48067, 3, 978302109), ('My Fair Lady (1964)', 'Musical', 1, 'F', 1, 10, 48067, 3, 978301968), ('Erin Brockovich (2000)', 'Drama', 1, 'F', 1, 10, 48067, 4, 978300275), (\"Bug's Life A (1998)\", 'Animation', 1, 'F', 1, 10, 48067, 5, 978824291), ('Princess Bride The (1987)', 'Action', 1, 'F', 1, 10, 48067, 3, 978302268), ('Ben-Hur (1959)', 'Action', 1, 'F', 1, 10, 48067, 5, 978302039), ('Christmas Story A (1983)', 'Comedy', 1, 'F', 1, 10, 48067, 5, 978300719), ('Snow White and the Seven Dwarfs (1937)', 'Animation', 1, 'F', 1, 10, 48067, 4, 978302268), ('Wizard of Oz The (1939)', 'Adventure', 1, 'F', 1, 10, 48067, 4, 978301368)]\n"
     ]
    }
   ],
   "source": [
    "search_results = cur.fetchmany(10)\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results1 = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert query to objects of key-value pairs\n",
    "objects_list = []\n",
    "for row in search_results1:\n",
    "    d = collections.OrderedDict()\n",
    "    d['Title'] = row[0]\n",
    "    d['Genre'] = row[1]\n",
    "    d['UserID'] = row[2]\n",
    "    d['Gender'] = row[3]\n",
    "    d['Age'] = row[4]\n",
    "    d['Occupation'] = row[5]\n",
    "    d['ZipCode'] = row[6]\n",
    "    d['Rating'] = row[7]\n",
    "    d['Timestamp'] = row[8]\n",
    "    objects_list.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the sql query to json\n",
    "with open('ml-1m/nosql_data.json', 'w') as outfile:\n",
    "    json.dump(objects_list, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB, Query, where\n",
    "\n",
    "tiny_db = TinyDB('ml-1m/ml_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I tried to use the 'insert_multiple' and it did not work me \n",
    "#So this was the only method that work for me and since it takes too long,\n",
    "#I just inserted the first 10000 rows to save time \n",
    "# This version gets all the rows\n",
    "#for i in range(len(objects_list)):\n",
    "#    tiny_db.insert(objects_list)\n",
    "\n",
    "i = 0\n",
    "while i < 10001:\n",
    "    tiny_db.insert(objects_list[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the relational database you built, compare M and F average ratings for \"Die Hard.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_query = \"\"\"Select m.Title, u.Gender, avg(r.Rating)\n",
    "from Movies m \n",
    "inner join Ratings r on m.MovieID = r.MovieID \n",
    "inner join Users u on r.UserID = u.UserID \n",
    "where u.Gender = 'F' and m.Title = 'Die Hard (1988)'\n",
    "group by m.Title, u.Gender;\"\"\"\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Die Hard (1988)', 'F', Decimal('3.9185667752442997'))]\n"
     ]
    }
   ],
   "source": [
    "search_resultsF = cur.fetchall()\n",
    "print(search_resultsF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_query = \"\"\"Select m.Title, u.Gender, avg(r.Rating)\n",
    "from Movies m \n",
    "inner join Ratings r on m.MovieID = r.MovieID \n",
    "inner join Users u on r.UserID = u.UserID \n",
    "where u.Gender = 'M' and m.Title = 'Die Hard (1988)'\n",
    "group by m.Title, u.Gender;\"\"\"\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Die Hard (1988)', 'M', Decimal('4.1677704194260486'))]\n"
     ]
    }
   ],
   "source": [
    "search_resultsM = cur.fetchall()\n",
    "print(search_resultsM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Do the same comparison with the NoSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_dh_set = tiny_db.search( (where('Title').matches('Die Hard')) & (where('Gender').matches('F')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_avg_f = sum(int(r['Rating']) for r in female_dh_set) / len(female_dh_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 3.0\n"
     ]
    }
   ],
   "source": [
    "print('Average: {}'.format(dh_avg_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_dh_set = tiny_db.search( (where('Title').matches('Die Hard')) & (where('Gender').matches('M')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_avg_m = sum(int(r['Rating']) for r in male_dh_set) / len(male_dh_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 3.769230769230769\n"
     ]
    }
   ],
   "source": [
    "print('Average: {}'.format(dh_avg_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Do the averages match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, but the reason is that I use a smaller portion of the dataset in the TinyDB instead of the full dataset. However, if I were able to use the full dataset I think that both the Sql and NoSql averages would be similiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the age range of female reviewers of \"Gone With The Wind?\" (Hint: in SQL, you can use a column more than once. Hint 2: There may be built in functions that help.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_age(movie_title,gender, avg_column):\n",
    "    female_dh_set = tiny_db.search( (where('Title').matches(movie_title)) & (where('Gender').matches(gender)) )\n",
    "    dh_avg_f = sum(int(u[avg_column]) for u in female_dh_set) / len(female_dh_set)\n",
    "    return 'Average: {}'.format(dh_avg_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Average: 36.8'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_age('Gone with the Wind', 'F', 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_query = \"\"\"Select m.Title, u.Gender, avg(u.Age)\n",
    "from Movies m \n",
    "inner join Ratings r on m.MovieID = r.MovieID \n",
    "inner join Users u on r.UserID = u.UserID \n",
    "where u.Gender = 'F' and m.Title = 'Gone with the Wind (1939)'\n",
    "group by m.Title, u.Gender;\"\"\"\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(age_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gone with the Wind (1939)', 'F', Decimal('32.8956916099773243'))]\n"
     ]
    }
   ],
   "source": [
    "search_results_Age = cur.fetchall()\n",
    "print(search_results_Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Sql to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(postgresql_select4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ml-1m/sql_query_out.csv\", \"w\", newline='') as csv_file:  # Python 3 version    \n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([i[0] for i in cur.description]) # write headers\n",
    "    csv_writer.writerows(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
